{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Storm Data\n",
    "\n",
    "Recently, the _International Hurricane Watchgroup_ (IHW) has been asked to update their analysis tools. Because of the increase in public awareness of hurricanes, they are required to be more diligient with the analysis of historical hurricane data they share across the organization. They have asked us to help work with their team to productionize their services.\n",
    "\n",
    "Accepting the job, their team tells us that they have been having trouble sharing data across the teams and keeping it consistent. From what they've told us, it seems that their method of sharing the data with their data anaylsts has been to save a CSV file on their local servers and have every data analyst pull the data down. Then, each analyst uses a local SQLite engine to store the CSV, run their queries, and send their results around.\n",
    "\n",
    "From what they have toldus, we think that this is an inefficient way of sharing data. To understand what we will be working on, they have sent us a CSV file. Their CSV file contains the following fields:\n",
    "\n",
    "- `fid` - ID for the row\n",
    "- `year` - Recorded year\n",
    "- `month` - Recorded month\n",
    "- `day` - Recorded date\n",
    "- `ad_time` - Recorded time in UTC\n",
    "- `btid` - Hurricane ID\n",
    "- `name` - Name of the hurricane\n",
    "- `lat` - Latitude of the recorded location\n",
    "- `long` - Longitude of the recorded location\n",
    "- `wind_kts` - Wind speed in knots per second\n",
    "- `pressure` - Atmospheric pressure of the hurricane\n",
    "- `cat` - Hurricane category\n",
    "- `basin` - The basin the hurricane is located\n",
    "- `shape_leng` - Hurricane shape length\n",
    "\n",
    "We need to create a database that will accomplish the following requirements:\n",
    "\n",
    "- Database for the IHW to store their tables.\n",
    "- Table that contains the fields detailed in the CSV file\n",
    "- User that can update, read, and insert into a table of the data.\n",
    "- Insert the data into the table.\n",
    "\n",
    "\n",
    "[File Download Link](https://dq-content.s3.amazonaws.com/251/storm_data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import csv\n",
    "import datetime\n",
    "import psycopg2\n",
    "\n",
    "import pandas as pd\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Helper Functions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the uniqueness of each column's values\n",
    "def display_columns_unique_values(df):\n",
    "    '''display each columns unique values\n",
    "        - if only 1, will display it\n",
    "        - if unable to get unique values, will display data structure type\n",
    "    '''\n",
    "    for column in df.columns:\n",
    "\n",
    "        try:\n",
    "            unique_values = df[column].unique()\n",
    "            num_unique_values = len(unique_values)\n",
    "            result = f\"Column {column.upper():>15}: {num_unique_values:}\"\n",
    "\n",
    "            if num_unique_values == 1:\n",
    "                result += f\"|Unique values: {unique_values}\"\n",
    "\n",
    "            print(result)\n",
    "\n",
    "        # some columns contain dict objects which aren't hashable so they are ignored\n",
    "        except TypeError as tp:\n",
    "            print(f\"Column {column.upper()}: Type: {type(df[column][0])}\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project01_storing_storm_data.ipynb  storm_data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alternative approach: _download the file_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffFID', 'YEAR', 'MONTH', 'DAY', 'AD_TIME', 'BTID', 'NAME', 'LAT', 'LONG', 'WIND_KTS', 'PRESSURE', 'CAT', 'BASIN', 'Shape_Leng']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "from urllib import request\n",
    "\n",
    "file_link = 'https://dq-content.s3.amazonaws.com/251/storm_data.csv'\n",
    "\n",
    "response = request.urlopen(file_link)\n",
    "reader = csv.reader(io.TextIOWrapper(response))\n",
    "\n",
    "for line in reader:\n",
    "    print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('storm_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>AD_TIME</th>\n",
       "      <th>BTID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>WIND_KTS</th>\n",
       "      <th>PRESSURE</th>\n",
       "      <th>CAT</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>Shape_Leng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>1957</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1800Z</td>\n",
       "      <td>63</td>\n",
       "      <td>NOTNAMED</td>\n",
       "      <td>22.5</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.140175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>1961</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1200Z</td>\n",
       "      <td>116</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>22.1</td>\n",
       "      <td>-140.2</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.166190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>1962</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>0600Z</td>\n",
       "      <td>124</td>\n",
       "      <td>C</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.102380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>1967</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0600Z</td>\n",
       "      <td>168</td>\n",
       "      <td>DENISE</td>\n",
       "      <td>16.6</td>\n",
       "      <td>-139.5</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.121320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>1972</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1200Z</td>\n",
       "      <td>251</td>\n",
       "      <td>DIANA</td>\n",
       "      <td>18.5</td>\n",
       "      <td>-139.8</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>H1</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.702939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FID  YEAR  MONTH  DAY AD_TIME  BTID      NAME   LAT   LONG  WIND_KTS  \\\n",
       "0  2001  1957      8    8   1800Z    63  NOTNAMED  22.5 -140.0        50   \n",
       "1  2002  1961     10    3   1200Z   116   PAULINE  22.1 -140.2        45   \n",
       "2  2003  1962      8   29   0600Z   124         C  18.0 -140.0        45   \n",
       "3  2004  1967      7   14   0600Z   168    DENISE  16.6 -139.5        45   \n",
       "4  2005  1972      8   16   1200Z   251     DIANA  18.5 -139.8        70   \n",
       "\n",
       "   PRESSURE CAT            BASIN  Shape_Leng  \n",
       "0         0  TS  Eastern Pacific    1.140175  \n",
       "1         0  TS  Eastern Pacific    1.166190  \n",
       "2         0  TS  Eastern Pacific    2.102380  \n",
       "3         0  TS  Eastern Pacific    2.121320  \n",
       "4         0  H1  Eastern Pacific    1.702939  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59228, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column             FID: 59228\n",
      "Column            YEAR: 158\n",
      "Column           MONTH: 12\n",
      "Column             DAY: 31\n",
      "Column         AD_TIME: 4\n",
      "Column            BTID: 1410\n",
      "Column            NAME: 482\n",
      "Column             LAT: 582\n",
      "Column            LONG: 1950\n",
      "Column        WIND_KTS: 61\n",
      "Column        PRESSURE: 131\n",
      "Column             CAT: 12\n",
      "Column           BASIN: 2\n",
      "Column      SHAPE_LENG: 957\n"
     ]
    }
   ],
   "source": [
    "display_columns_unique_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore each column's unique values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       18\n",
       "2       25\n",
       "3       25\n",
       "4       55\n",
       "5       23\n",
       "6       21\n",
       "7       64\n",
       "8       19\n",
       "9       31\n",
       "10      73\n",
       "11      27\n",
       "12      17\n",
       "13       9\n",
       "14      61\n",
       "15      15\n",
       "16       5\n",
       "17      25\n",
       "18      29\n",
       "19      33\n",
       "20      26\n",
       "21      21\n",
       "22      35\n",
       "23      17\n",
       "24      27\n",
       "25       9\n",
       "26      17\n",
       "27      29\n",
       "28      23\n",
       "29      17\n",
       "30      21\n",
       "        ..\n",
       "1381    22\n",
       "1382    22\n",
       "1383    39\n",
       "1384    19\n",
       "1385    25\n",
       "1386    13\n",
       "1387     9\n",
       "1388    25\n",
       "1389     7\n",
       "1390    18\n",
       "1391    12\n",
       "1392    30\n",
       "1393    52\n",
       "1394    23\n",
       "1395     8\n",
       "1396    72\n",
       "1397    17\n",
       "1398    26\n",
       "1399    13\n",
       "1400    51\n",
       "1401    46\n",
       "1402    46\n",
       "1403    57\n",
       "1404    32\n",
       "1405    22\n",
       "1406    33\n",
       "1407     7\n",
       "1408    13\n",
       "1409    31\n",
       "1410    34\n",
       "Name: BTID, Length: 1410, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BTID'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOTNAMED', 'PAULINE', 'C', 'DENISE', 'DIANA', 'KRISTY', 'KAY',\n",
       "       'MAGGIE', 'GREG', 'JOVA', 'DANIEL', 'DOUGLAS', 'HECTOR', 'ERICK',\n",
       "       'CELESTE', 'GEORGETTE', 'ORLENE', 'YOLANDA', 'EUGENE', 'FERNANDA',\n",
       "       'LANE', 'DOLORES', 'KATHERINE', 'DORA', 'BARBARA', 'NARDA', 'IONE',\n",
       "       'GUILLERMO', 'JIMENA', 'BUD', 'ELIDA', 'KANOA', 'ROSALIE', 'DOT',\n",
       "       'CONNIE', 'RAMONA', 'KATE', 'KATHLEEN', 'LORRAINE', 'HILARY',\n",
       "       'JOHN', 'DOREEN', 'MIRIAM', 'PATRICIA', 'FICO', 'EMILIA', 'GILMA',\n",
       "       'EMA', 'SONIA', 'GIL', 'KENNA', 'KENNETH', 'RAYMOND', 'LINDA',\n",
       "       'RICK', 'FAUSTO', 'ESTELLE', 'MARIE', 'POLO', 'FEFA', 'JAVIER',\n",
       "       'ROSLYN', 'FABIO', 'FELICIA', 'DARBY', 'IRAH', 'ELEANOR',\n",
       "       'CLAUDIA', 'HERNAN', 'HENRIETTE', 'ISMAEL', 'JULIO', 'ENRIQUE',\n",
       "       'KEVIN', 'BLANCA', 'LALA', 'MADELINE', 'GWEN', 'HYACINTH', 'MARTY',\n",
       "       'FRANK', 'IGNACIO', 'ALIKA', 'LOWELL', 'ALETTA', 'ANDRES', 'ISIS',\n",
       "       'TARA', 'WILA', 'DALILIA', 'BORIS', 'GENEVIEVE', 'IOKE', 'COSME',\n",
       "       'INIKI', 'GRETCHEN', 'FLOSSIE', 'SANDRA', 'CRISTINA', 'KIKA',\n",
       "       'LESTER', 'ORLA', 'TINA', 'OTIS', 'LI', 'KELI', 'HIKI', 'KEONI',\n",
       "       'SUSAN', 'DELLA', 'SARAH', 'WANDA', 'OKA', 'ULEKI', 'UPANA',\n",
       "       'OLIVE', 'AKA', 'EKEKA', 'HUKO', 'CARLOTTA', 'HOWARD', 'BLAS',\n",
       "       'NEWTON', 'BEATRIZ', 'OCTAVE', 'CELIA', 'ODILE', 'CARLOS',\n",
       "       'FLORENCE', 'GLENDA', 'NORBERT', 'SIMON', 'AVA', 'FRANCESCA',\n",
       "       'AGATHA', 'BERNICE', 'HEATHER', 'SERGIO', 'IVA', 'KIRSTEN',\n",
       "       'ADOLPH', 'IWA', 'NINA', 'JUNE', 'HALI', 'RUBY', 'AKONI', 'PATSY',\n",
       "       'HANA', 'PAKA', 'PEKE', 'NELE', 'MELE', 'ELE', 'NONA', 'OLIWA',\n",
       "       'ADRIAN', 'HILDA', 'PAUL', 'ALVIN', 'NAOMI', 'JEN-KATH', 'ODESSA',\n",
       "       'VICTORIA', 'PRUDENCE', 'JOYCE', 'NORMAN', 'LILY', 'NANETTE',\n",
       "       'ADELE', 'JOANNE', 'RACHEL', 'FRANCENE', 'VIVIAN', 'XINA', 'EMILY',\n",
       "       'LILLIAN', 'HELGA', 'BRIDGET', 'JEWEL', 'CALVIN', 'MONICA', 'KNUT',\n",
       "       'ALMA', 'JULIETTE', 'PRISCILLA', 'KIKO', 'OLIVIA', 'LORENA',\n",
       "       'NORA', 'ISELLE', 'OLAF', 'ILSA', 'MAX', 'RAMON', 'IRWIN',\n",
       "       'MANUEL', 'SEYMOUR', 'TRUDY', 'NORMA', 'LIZA', 'PAINE', 'WILLA',\n",
       "       'DALILA', 'BONNY', 'EILEEN', 'KATRINA', 'ILEANA', 'DALIA',\n",
       "       'REBECCA', 'SELMA', 'ZEKE', 'LIDIA', 'TERRY', 'VANCE', 'IVO',\n",
       "       'KARINA', 'ANNETTE', 'TILLIE', 'ROSA', 'JENNIFER', 'IONE2',\n",
       "       'KRISTEN', 'DELORES', 'XAVIER', 'MONA', 'SHARON', 'PILAR', 'TICO',\n",
       "       'HAZEL', 'DEBBY', 'WALDO', 'VALERIE', 'NATALIE', 'VIRGIL', 'DOLLY',\n",
       "       'IONE1', 'WINNIE', 'WINIFRED', 'VELMA', 'FIFI', 'GERT', 'ANITA',\n",
       "       'WALLIE', 'CHARLIE', 'INEZ', 'ELLA', 'KEITH', 'GLADYS', 'ITEM',\n",
       "       'GEORGE', 'JANET', 'ANNA', 'LARRY', 'SIMONE', 'JOSE', 'STAN',\n",
       "       'DEAN', 'FELIX', 'LORENZO', 'MARCO', 'ALICE', 'AUDREY', 'ESTHER',\n",
       "       'MITCH', 'BEULAH', 'IRENE', 'INGA', 'HALLIE', 'FERN', 'LAURIE',\n",
       "       'ABBY', 'GRETA', 'EDITH', 'CAROLINE', 'BRENDA', 'BESS', 'BOB',\n",
       "       'HENRI', 'HERMINE', 'ALLEN', 'JUAN', 'JERRY', 'GILBERT', 'ARLENE',\n",
       "       'GABRIELLE', 'OPAL', 'ROXANNE', 'EARL', 'FRANCES', 'BRET', 'BERYL',\n",
       "       'MATTHEW', 'CHANTAL', 'CANDY', 'JOSEPHINE', 'EDOUARD', 'HOW',\n",
       "       'DEBBIE', 'DELIA', 'ELOISE', 'JEANNE', 'GORDON', 'ISIDORE', 'BILL',\n",
       "       'CLAUDETTE', 'BONNIE', 'CINDY', 'ALBERTO', 'OLGA', 'BAKER',\n",
       "       'DANNY', 'WILMA', 'FRANCELIA', 'CHLOE', 'LAURA', 'ARTHUR', 'AGNES',\n",
       "       'CARMEN', 'FRIEDA', 'KYLE', 'DEBRA', 'LILI', 'IRIS', 'CESAR',\n",
       "       'ERIN', 'GILDA', 'FLOSSY', 'HATTIE', 'CARLA', 'GAMMA', 'BARRY',\n",
       "       'JUDITH', 'BECKY', 'ALLISON', 'RITA', 'GUSTAV', 'CAMILLE',\n",
       "       'SUBTROP1', 'JOAN', 'BETA', 'FLOYD', 'ISBELL', 'FREDERIC', 'IVAN',\n",
       "       'IKE', 'KAREN', 'FABIAN', 'HELENE', 'KING', 'FOX', 'EASY', 'ELENA',\n",
       "       'MICHELLE', 'JENNY', 'CHARLEY', 'DENNIS', 'PALOMA', 'MARTHA',\n",
       "       'JANICE', 'DONNA', 'CLEO', 'DAWN', 'GEORGES', 'CHRIS', 'ERNESTO',\n",
       "       'FAY', 'DOG', 'LENNY', 'NOEL', 'KATIE', 'DANIELLE', 'GERDA',\n",
       "       'FLORA', 'SUBTROP4', 'DAVID', 'ODETTE', 'GRACIE', 'DOROTHY',\n",
       "       'ALPHA', 'HANNA', 'MINDY', 'EDNA', 'BETSY', 'ETHEL', 'KARA',\n",
       "       'BERTHA', 'DORIA', 'GINNY', 'KENDRA', 'KLAUS', 'MARILYN', 'FRAN',\n",
       "       'HORTENSE', 'ISABEL', 'SUBTROP', 'GRACE', 'JULIET', 'OMAR', 'ABLE',\n",
       "       'FAITH', 'GLORIA', 'HUGO', 'CHRISTINE', 'HOLLY', 'GERTRUDE',\n",
       "       'CORA', 'ANA', 'DAISY', 'LUIS', 'SEBASTIEN', 'HEIDI', 'ELAINE',\n",
       "       'EMMY', 'CAROL', 'ERIKA', 'NANA', 'ANDREW', 'HELENA', 'INGRID',\n",
       "       'HARVEY', 'NICHOLAS', 'LEE', 'ISAAC', 'PABLO', 'PHILIPPE', 'ALEX',\n",
       "       'FAYE', 'DIANE', 'LOIS', 'JIG', 'KARL', 'MARIA', 'ZETA', 'MELISSA',\n",
       "       'LISA', 'CARRIE', 'GAIL', 'HUMBERTO', 'ELLEN', 'PETER', 'DELTA',\n",
       "       'GINGER', 'HANNAH', 'TANYA', 'NICOLE', 'SUBTROP2', 'EPSILON',\n",
       "       'BETTY', 'NATE', 'IRMA', 'VINCE', 'HOPE', 'OTTO', 'DORIS',\n",
       "       'NADINE', 'AMY', 'CANDICE', 'FRANKLIN', 'CLARA', 'GASTON',\n",
       "       'MICHAEL', 'CRISTOBAL', 'EVELYN', 'LESLIE', 'SUBTROP3', 'OPHELIA',\n",
       "       'BETH', 'BLANCHE', 'ALFA', 'EVE', 'ANDREA', 'BELLE', 'FELICE',\n",
       "       'DOTTIE', 'TAMMY', 'BABE', 'LOVE', 'ALICIA', 'AMELIA', 'MOKE',\n",
       "       'WENE'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NAME'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of name: 9\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for name in df['NAME'].unique():\n",
    "    max_len = max(max_len, len(name))\n",
    "print('Max length of name:', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 50,  45,  70,  30,  75,  60, 100,  35,  40,  25,  80,  85,  90,\n",
       "        15,  65,  20,  95,  55, 110, 120, 125, 115, 105, 130, 135, 140,\n",
       "       150, 145,  77,  84, 155,  67, 160,  10, 165,  34,  43,  52,  28,\n",
       "        29,  27,  87, 102,  98,  94,  33,  32,  31,  62, 118, 117,  54,\n",
       "        56,  68,  58,  82,  63,  37,  48,  93,  78])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['WIND_KTS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10       59\n",
       "15      196\n",
       "20      916\n",
       "25     5056\n",
       "27        2\n",
       "28        3\n",
       "29        2\n",
       "30     5980\n",
       "31        2\n",
       "32        2\n",
       "33        2\n",
       "34        1\n",
       "35     6002\n",
       "37        1\n",
       "40     4957\n",
       "43        2\n",
       "45     6052\n",
       "48        1\n",
       "50     4303\n",
       "52        2\n",
       "54        1\n",
       "55     2488\n",
       "56        1\n",
       "58        1\n",
       "60     3272\n",
       "62        2\n",
       "63        3\n",
       "65     2682\n",
       "67        1\n",
       "68        2\n",
       "       ... \n",
       "75     2866\n",
       "77        6\n",
       "78        2\n",
       "80     2151\n",
       "82        1\n",
       "84        3\n",
       "85     1738\n",
       "87        1\n",
       "90     2075\n",
       "93        1\n",
       "94        1\n",
       "95      889\n",
       "98        1\n",
       "100    1160\n",
       "102       2\n",
       "105     794\n",
       "110     650\n",
       "115     520\n",
       "117       1\n",
       "118       1\n",
       "120     395\n",
       "125     261\n",
       "130     172\n",
       "135      95\n",
       "140     112\n",
       "145      32\n",
       "150      21\n",
       "155      13\n",
       "160       8\n",
       "165       3\n",
       "Name: WIND_KTS, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['WIND_KTS'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 1005, 1012, 1007, 1002, 1011,  997,  973,  992, 1010, 1008,\n",
       "        960,  968, 1006, 1009, 1000, 1003,  972,  975, 1004,  994,  976,\n",
       "        990,  995,  980,  999,  996,  998,  955,  985,  969,  963,  987,\n",
       "       1014,  970,  966,  974, 1001,  979,  984,  946,  950,  978,  961,\n",
       "        948,  981,  988,  977,  965, 1013,  989,  993,  944,  952, 1015,\n",
       "        986,  949,  991,  962,  958,  935,  928,  926,  929,  936,  932,\n",
       "        940,  982,  951,  956,  943,  957,  953,  930,  920,  959,  945,\n",
       "        954,  983,  964,  933,  941,  947,  939,  938,  971,  921,  900,\n",
       "        919,  924,  923,  967,  937,  942,  934,  925,  910,  915,  927,\n",
       "        931,  906,  903,  905,  917,  902,  913,  907,  892,  899,  914,\n",
       "        888,  889,  922,  912,  901,  916,  882,  911,  918, 1016, 1020,\n",
       "       1017, 1018, 1019, 1021, 1022, 1023, 1024,  908,  897,  909])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PRESSURE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       37002\n",
       "882         1\n",
       "888         1\n",
       "889         1\n",
       "892         5\n",
       "897         2\n",
       "899         1\n",
       "900         6\n",
       "901         1\n",
       "902         2\n",
       "903         1\n",
       "905         5\n",
       "906         2\n",
       "907         1\n",
       "908         2\n",
       "909         3\n",
       "910        23\n",
       "911         1\n",
       "912         2\n",
       "913         3\n",
       "914         4\n",
       "915         7\n",
       "916         3\n",
       "917         3\n",
       "918         1\n",
       "919         4\n",
       "920        18\n",
       "921        12\n",
       "922         4\n",
       "923        12\n",
       "        ...  \n",
       "995       497\n",
       "996       301\n",
       "997       564\n",
       "998       453\n",
       "999       389\n",
       "1000     1146\n",
       "1001      456\n",
       "1002      766\n",
       "1003      716\n",
       "1004      740\n",
       "1005     1248\n",
       "1006      969\n",
       "1007      924\n",
       "1008      961\n",
       "1009     1172\n",
       "1010      830\n",
       "1011      361\n",
       "1012      329\n",
       "1013      155\n",
       "1014      106\n",
       "1015       51\n",
       "1016       28\n",
       "1017       15\n",
       "1018        9\n",
       "1019        5\n",
       "1020       12\n",
       "1021        4\n",
       "1022        4\n",
       "1023        4\n",
       "1024        1\n",
       "Name: PRESSURE, Length: 131, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PRESSURE'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TS', 'H1', 'TD', 'H3', 'H2', 'L', 'H4', 'H5', 'E', 'W', 'SS',\n",
       "       'SD'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CAT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Eastern Pacific', 'North Atlantic'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BASIN'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Types to Use**:\n",
    "\n",
    "- `fid` - Row ID - Integer\n",
    "- `year`, `month`, `day`, `ad_time` - combine into timestamp with timezone\n",
    "- `btid` - Hurricane ID - smallint\n",
    "- `name` - Name of the hurricane - TEXT\n",
    "- `lat` - Latitude of the recorded location - smallint\n",
    "- `long` - Longitude of the recorded location - smallint\n",
    "- `wind_kts` - Wind speed in knots per second - smallint\n",
    "- `pressure` - Atmospheric pressure of the hurricane - smallint\n",
    "- `cat` - Hurricane category - VARCHAR(2)\n",
    "- `basin` - The basin the hurricane is located - TEXT\n",
    "- `shape_leng` - Hurricane shape length - Decimal with 1 digit before the decimal and 6 digits after it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Database and Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"johannes\", user=\"johannes\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Autocommit instead of committing every transaction - needed to create DB\n",
    "conn.autocommit = True\n",
    "\n",
    "cursor.execute('CREATE DATABASE ihw')\n",
    "cursor.execute(\"CREATE USER production WITH PASSWORD 'abc123'\")\n",
    "cursor.execute(\"CREATE USER analyst WITH PASSWORD 'def456'\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"ihw\", user=\"johannes\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE hurricanes(\n",
    "    fid INTEGER PRIMARY KEY,\n",
    "    recorded_at TIMESTAMP,\n",
    "    btid INTEGER,\n",
    "    name VARCHAR(10),\n",
    "    lat DECIMAL(4, 1),\n",
    "    long DECIMAL(4, 1),\n",
    "    wind_kts SMALLINT,\n",
    "    pressure INTEGER,\n",
    "    category VARCHAR(2),\n",
    "    basin VARCHAR(16),\n",
    "    shape_leng DECIMAL(8, 6)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage User Privileges\n",
    "\n",
    "With a table set up, it's now time to create a user on the Postgres database that can insert, update, and read the data but not delete. This is to make sure that someone who might get a hold of this user does not issue a destructive command. Essentially, this is like creating a \"data production\" user whose job it is is to always write new and existing data to the table.\n",
    "\n",
    "Futhermore, even though it wasn't according to the spec, we know that the IHW team's analysts just run read queries on the data. Also, since the analysts only know SQLite queries, they may not be well-versed in a production database. As such, it might be risky handing out a general production user for them to query their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"ihw\", user=\"johannes\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "REVOKE ALL ON hurricanes FROM production;\n",
    "REVOKE ALL ON hurricanes FROM analyst;\n",
    "GRANT SELECT, INSERT, UPDATE ON hurricanes TO production;\n",
    "GRANT SELECT ON hurricanes TO analyst;\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unable to login to database as user 'production' --> will try via regular py script\n",
    "conn = psycopg2.connect(dbname='ihw', user='johannes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname='ihw', user='johannes')\n",
    "cursor = conn.cursor()\n",
    "conn.autocommit = True\n",
    "\n",
    "with open('storm_data.csv', 'r') as f:\n",
    "    \n",
    "    next(f) # skip header line\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    rows = []\n",
    "    for row in reader:\n",
    "        #print(row)\n",
    "        recorded_at = datetime.datetime(int(row[1]), int(row[2]), int(row[3]), \n",
    "                                        hour=int(row[4][:2]), minute=int(row[4][2:-1]))\n",
    "        \n",
    "        new_row = [row[0], recorded_at] + row[5:]\n",
    "        #print(new_row)\n",
    "        rows.append(\n",
    "            cursor.mogrify(\n",
    "                \"(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\",\n",
    "                new_row\n",
    "            ).decode('utf-8')\n",
    "        )\n",
    "    \n",
    "    #pp.pprint(rows[:10])\n",
    "        \n",
    "    cursor.execute(\"INSERT INTO hurricanes VALUES \" + \",\".join(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(59228,)]\n"
     ]
    }
   ],
   "source": [
    "# validate data\n",
    "cursor.execute('select count(1) from hurricanes')\n",
    "pp.pprint(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59228, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> This matches the number of rows in our original dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's just a small list of features we can add to our Postgres Database:\n",
    "\n",
    "- A `readonly` group instead of just one `readonly` user.\n",
    "- Try downloading the following [file](https://dq-content.s3.amazonaws.com/251/storm_data_additional.csv) that contains a new dataset that is slightly different.\n",
    "    - See if you can insert it in your created table.\n",
    "- Launch your Postgres instance! Right now only you have access to your data on your local machine. To share it, you need to use something like a **cloud-storage solution**.\n",
    "    - [Launch Postgres on AWS](https://aws.amazon.com/getting-started/tutorials/create-connect-postgresql-db/)\n",
    "    - [Launch Postgres with Heroku](https://www.heroku.com/postgres)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
